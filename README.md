# üé§ Transcriptor Modular Speech-to-Text# üé§ Transcriptor Modular Speech-to-Text# üé§ Transcriptor Modular Speech-to-Text



Sistema avanzado de transcripci√≥n de voz a texto con **arquitectura modular** que soporta 4 motores de transcripci√≥n diferentes. Incluye detecci√≥n de fraude en tiempo real con machine learning.## üì¶ Instalaci√≥n de Motores Adicionales



## üöÄ Caracter√≠sticasSistema avanzado de transcripci√≥n de voz a texto con **arquitectura modular** que soporta 4 motores de transcripci√≥n diferentes. Incluye detecci√≥n de fraude en tiempo real con machine learning.



- **4 motores de transcripci√≥n**: DeepSpeech (Google SR), Whisper, Silero, VoskPara instalar Whisper, Silero y Vosk (opcional):

- **Transcripci√≥n en tiempo real** con WebSockets (SocketIO)

- **Detecci√≥n de fraude con ML** (LogisticRegression + TF-IDF)## üöÄ Caracter√≠sticas```bash

- **Interfaz web moderna** con Bootstrap 5

- **Configuraci√≥n flexible** de audio en tiempo real.\instalar_motores.bat

- **Arquitectura modular** f√°cilmente extensible

- **4 motores de transcripci√≥n**: DeepSpeech, Whisper, Silero, Vosk```

## üîß Motores Disponibles

- **Transcripci√≥n en tiempo real** con SocketIO

| Motor | Velocidad | Precisi√≥n | Internet | Recursos |

|-------|-----------|-----------|----------|----------|- **Detecci√≥n de fraude con ML** (LogisticRegression + TF-IDF)## üìÅ Estructura del Proyecto

| **DeepSpeech** (Google SR) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Requiere | Bajo |

| **OpenAI Whisper** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Alto |- **Interfaz web moderna** con Bootstrap 5

| **Silero STT** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Medio |

| **Vosk** (Kaldi) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Bajo |- **Configuraci√≥n flexible** de audio en tiempo real```



## üöÄ Inicio R√°pido- **Arquitectura modular** f√°cilmente extensibleDTIC_V4_DeepSpeech/



### Instalaci√≥n‚îú‚îÄ‚îÄ transcriptor.py              # Servidor principal con interfaz integrada



```bash## üîß Motores Disponibles‚îú‚îÄ‚îÄ engine_manager.py            # Gestor de motores de transcripci√≥n

# 1. Clonar repositorio

git clone https://github.com/tu-usuario/DTIC_V4_DeepSpeech.git‚îú‚îÄ‚îÄ engines/                     # Motores de transcripci√≥n

cd DTIC_V4_DeepSpeech

| Motor | Velocidad | Precisi√≥n | Internet | Recursos |‚îÇ   ‚îú‚îÄ‚îÄ base_engine.py          #   Clase base para motores

# 2. Crear entorno virtual

python -m venv transcriptor_env|-------|-----------|-----------|-----------|-----------|‚îÇ   ‚îú‚îÄ‚îÄ deepspeech_engine.py    #   Motor Google Speech Recognition



# 3. Activar entorno (Windows)| **DeepSpeech** (Google SR) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Requiere | Bajo |‚îÇ   ‚îú‚îÄ‚îÄ whisper_engine.py       #   Motor OpenAI Whisper

.\transcriptor_env\Scripts\activate

| **OpenAI Whisper** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Alto |‚îÇ   ‚îú‚îÄ‚îÄ silero_engine.py        #   Motor Silero STT

# 4. Instalar dependencias

pip install -r requirements.txt| **Silero STT** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Medio |‚îÇ   ‚îî‚îÄ‚îÄ vosk_engine.py          #   Motor Vosk/Kaldi

```

| **Vosk** (Kaldi) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Bajo |‚îú‚îÄ‚îÄ models/                      # Modelos de Vosk

### Ejecutar

‚îú‚îÄ‚îÄ transcriptor_env/            # Entorno virtual Python

```bash

# Opci√≥n 1: Script de inicio## üöÄ Inicio R√°pido‚îú‚îÄ‚îÄ best_model_lr.joblib         # Modelo ML detecci√≥n fraude

.\iniciar_transcriptor.bat

‚îú‚îÄ‚îÄ vectorizer_tfidf.joblib      # Vectorizador TF-IDF

# Opci√≥n 2: Manual

.\transcriptor_env\Scripts\activate### 1. Ejecutar el sistema‚îú‚îÄ‚îÄ requirements.txt             # Dependencias Python

python transcriptor.py

``````bash‚îî‚îÄ‚îÄ iniciar_transcriptor.bat     # Script inicio r√°pido



Abrir navegador en: **http://localhost:5003**# Doble clic en el archivo:```



## üì¶ Instalaci√≥n Completainiciar_transcriptor.bat



Para instrucciones detalladas de instalaci√≥n, consulta [INSTALL.md](INSTALL.md)## ‚öôÔ∏è Configuraci√≥n de Audio



## üéØ Uso# O desde l√≠nea de comandos:



### Interfaz Webtranscriptor_env\Scripts\activate- **Umbral de Energ√≠a**: Controla sensibilidad del micr√≥fono



1. **Seleccionar motor** - Haz clic en las tarjetas de motores disponiblespython transcriptor.py- **Pausa Entre Frases**: Tiempo de silencio para detectar fin de frase

2. **Configurar audio** - Ajusta los par√°metros seg√∫n tu ambiente:

   - **Umbral de Energ√≠a**: Sensibilidad del micr√≥fono (300-4000)```- **L√≠mite de Frase**: Tiempo m√°ximo de grabaci√≥n continua

   - **Pausa Entre Frases**: Tiempo de silencio para detectar fin de frase (0.1-2.0s)

   - **L√≠mite de Frase**: Duraci√≥n m√°xima de grabaci√≥n (3-15s)- **Timeout de Escucha**: Tiempo m√°ximo esperando inicio de voz

   - **Idioma**: Selecciona el idioma de transcripci√≥n

3. **Iniciar transcripci√≥n** - Presiona el bot√≥n "Iniciar" y habla### 2. Acceder a la interfaz- **Idioma**: Selecci√≥n de idioma para mejor precisi√≥n

4. **Ver resultados** - Las transcripciones aparecen en tiempo real con an√°lisis de fraude

Abrir navegador en: **http://localhost:5003**

### Detecci√≥n de Fraude

## üõ°Ô∏è Detecci√≥n de Fraude

El sistema analiza cada transcripci√≥n en tiempo real:

### 3. Usar el sistema

- üü¢ **Texto Normal**: Borde verde, probabilidad baja de fraude

- üî¥ **Fraude Detectado**: Borde rojo, probabilidad alta de fraude1. **Seleccionar motor** haciendo clic en las tarjetasEl sistema incluye un detector de fraude entrenado que analiza:

- üìä **Probabilidad**: Porcentaje de confianza del an√°lisis

2. **Ajustar configuraci√≥n** de audio si es necesario- **Keywords espec√≠ficas** relacionadas con fraudes

## üìÅ Estructura del Proyecto

3. **Hacer clic en "Iniciar"** para comenzar transcripci√≥n- **Patrones de texto** usando TF-IDF y regresi√≥n log√≠stica

```

DTIC_V4_DeepSpeech/4. **Hablar al micr√≥fono** - los resultados aparecen en tiempo real- **Probabilidad de fraude** en tiempo real

‚îú‚îÄ‚îÄ transcriptor.py              # Servidor principal con interfaz integrada

‚îú‚îÄ‚îÄ engine_manager.py            # Gestor de motores de transcripci√≥n

‚îú‚îÄ‚îÄ engines/                     # M√≥dulo de motores

‚îÇ   ‚îú‚îÄ‚îÄ base_engine.py          # Clase abstracta base## üì¶ Instalaci√≥n de Motores Adicionales## üîß Requisitos del Sistema

‚îÇ   ‚îú‚îÄ‚îÄ deepspeech_engine.py    # Motor Google Speech Recognition

‚îÇ   ‚îú‚îÄ‚îÄ whisper_engine.py       # Motor OpenAI Whisper

‚îÇ   ‚îú‚îÄ‚îÄ silero_engine.py        # Motor Silero STT

‚îÇ   ‚îî‚îÄ‚îÄ vosk_engine.py          # Motor Vosk/KaldiPara instalar Whisper, Silero y Vosk (opcional):- **Python 3.8+**

‚îú‚îÄ‚îÄ models/                      # Modelos de Vosk (descarga separada)

‚îú‚îÄ‚îÄ transcriptor_env/            # Entorno virtual Python```bash- **Windows 10/11** (PowerShell)

‚îú‚îÄ‚îÄ requirements.txt             # Dependencias b√°sicas

‚îú‚îÄ‚îÄ iniciar_transcriptor.bat     # Script de inicio r√°pido.\instalar_motores.bat- **Micr√≥fono** funcional

‚îú‚îÄ‚îÄ README.md                    # Este archivo

‚îú‚îÄ‚îÄ INSTALL.md                   # Gu√≠a de instalaci√≥n detallada```- **4GB RAM** m√≠nimo (8GB recomendado para Whisper)

‚îú‚îÄ‚îÄ CONTRIBUTING.md              # Gu√≠a de contribuci√≥n

‚îî‚îÄ‚îÄ LICENSE                      # Licencia MIT- **Conexi√≥n a internet** (solo para DeepSpeech)

```

## üìÅ Estructura del Proyecto

**Nota**: Los modelos de ML (`best_model_lr.joblib` y `vectorizer_tfidf.joblib`) se deben descargar por separado debido a su tama√±o.

## üìä Dependencias Principales

## ‚öôÔ∏è Configuraci√≥n de Audio

```

### Par√°metros Ajustables

DTIC_V4_DeepSpeech/- Flask 3.0.0 + Flask-SocketIO 5.3.6

- **Umbral de Energ√≠a**: Controla la sensibilidad del micr√≥fono

  - Valores altos = menos sensible (menos ruido de fondo)‚îú‚îÄ‚îÄ transcriptor.py              # Servidor principal con interfaz integrada- SpeechRecognition 3.10.0

  - Valores bajos = m√°s sensible (capta sonidos m√°s suaves)

  ‚îú‚îÄ‚îÄ engine_manager.py            # Gestor de motores de transcripci√≥n- PyAudio 0.2.14

- **Pausa Entre Frases**: Tiempo de silencio para detectar fin de frase

  - Valores bajos = respuesta m√°s r√°pida‚îú‚îÄ‚îÄ engines/                     # Motores de transcripci√≥n- scikit-learn 1.6.1

  - Valores altos = espera m√°s tiempo antes de procesar

‚îÇ   ‚îú‚îÄ‚îÄ base_engine.py          #   Clase base para motores- [Opcional] openai-whisper, silero-vad, vosk

- **L√≠mite de Frase**: Tiempo m√°ximo de grabaci√≥n continua

  - √ötil para frases muy largas‚îÇ   ‚îú‚îÄ‚îÄ deepspeech_engine.py    #   Motor Google Speech Recognition



- **Timeout de Escucha**: Tiempo m√°ximo esperando inicio de voz‚îÇ   ‚îú‚îÄ‚îÄ whisper_engine.py       #   Motor OpenAI Whisper## üêõ Soluci√≥n de Problemas

  - Si no detecta voz en este tiempo, para la grabaci√≥n

‚îÇ   ‚îú‚îÄ‚îÄ silero_engine.py        #   Motor Silero STT

- **Ajuste Din√°mico**: Adaptaci√≥n autom√°tica al ruido del ambiente

  - √ötil en lugares con ruido variable‚îÇ   ‚îî‚îÄ‚îÄ vosk_engine.py          #   Motor Vosk/Kaldi### Micr√≥fono no detectado



## üîß Requisitos del Sistema‚îú‚îÄ‚îÄ models/                      # Modelos de Vosk- Verificar permisos de micr√≥fono en Windows



- **Python 3.8+**‚îú‚îÄ‚îÄ transcriptor_env/            # Entorno virtual Python- Comprobar que no est√© siendo usado por otra aplicaci√≥n

- **Windows 10/11** (con PowerShell)

- **Micr√≥fono** funcional‚îú‚îÄ‚îÄ best_model_lr.joblib         # Modelo ML detecci√≥n fraude

- **4GB RAM** m√≠nimo (8GB recomendado para Whisper)

- **Conexi√≥n a internet** (solo para motor DeepSpeech)‚îú‚îÄ‚îÄ vectorizer_tfidf.joblib      # Vectorizador TF-IDF### Motor no disponible



## üìä Dependencias Principales‚îú‚îÄ‚îÄ requirements.txt             # Dependencias Python- Ejecutar `.\instalar_motores.bat` para instalar dependencias



```‚îî‚îÄ‚îÄ iniciar_transcriptor.bat     # Script inicio r√°pido- Verificar conexi√≥n a internet para DeepSpeech

Flask==3.0.0

Flask-SocketIO==5.3.6```

SpeechRecognition==3.10.0

PyAudio==0.2.14### Error de transcripci√≥n

scikit-learn==1.6.1

joblib==1.3.2## ‚öôÔ∏è Configuraci√≥n de Audio- Verificar nivel de ruido ambiental

numpy==1.24.3

```- Ajustar umbral de energ√≠a en configuraci√≥n



**Dependencias opcionales** (motores adicionales):- **Umbral de Energ√≠a**: Controla sensibilidad del micr√≥fono- Cambiar de motor de transcripci√≥n

- `openai-whisper` - Motor Whisper

- `torch` + `torchaudio` - Requerido para Whisper y Silero- **Pausa Entre Frases**: Tiempo de silencio para detectar fin de frase

- `vosk` - Motor Vosk/Kaldi

- **L√≠mite de Frase**: Tiempo m√°ximo de grabaci√≥n continua## üìù Logs y Debug

## üêõ Soluci√≥n de Problemas

- **Timeout de Escucha**: Tiempo m√°ximo esperando inicio de voz

### Micr√≥fono no detectado

- Verificar permisos de micr√≥fono en Windows- **Idioma**: Selecci√≥n de idioma para mejor precisi√≥nEl sistema incluye logging detallado:

- Comprobar que no est√© siendo usado por otra aplicaci√≥n

- Reiniciar el sistema- **Panel de debug** en la interfaz web



### Motor no disponible## üõ°Ô∏è Detecci√≥n de Fraude- **Consola del servidor** con informaci√≥n t√©cnica

- Ejecutar instalaci√≥n de dependencias adicionales

- Verificar conexi√≥n a internet para DeepSpeech- **Estados de SocketIO** en tiempo real

- Descargar modelos necesarios (Vosk)

El sistema incluye un detector de fraude entrenado que analiza:

### Error de transcripci√≥n

- Verificar nivel de ruido ambiental- **Keywords espec√≠ficas** relacionadas con fraudes---

- Ajustar umbral de energ√≠a en configuraci√≥n

- Cambiar de motor de transcripci√≥n- **Patrones de texto** usando TF-IDF y regresi√≥n log√≠stica



### PyAudio no se instala- **Probabilidad de fraude** en tiempo real**Desarrollado por**: Equipo DTIC  

```powershell

# Windows: Instalar desde pipwin**Versi√≥n**: 4.0  

pip install pipwin

pipwin install pyaudio## üîß Requisitos del Sistema**√öltima actualizaci√≥n**: Septiembre 2025ma avanzado de transcripci√≥n de voz a texto con **arquitectura modular** que soporta 4 motores de transcripci√≥n diferentes. Incluye detecci√≥n de fraude en tiempo real con machine learning.

```



## ü§ù Contribuir

- **Python 3.8+**## üöÄ Caracter√≠sticas

¬°Las contribuciones son bienvenidas! Por favor lee [CONTRIBUTING.md](CONTRIBUTING.md) para conocer el proceso.

- **Windows 10/11** (PowerShell)

### Pasos r√°pidos:

- **Micr√≥fono** funcional- **4 motores de transcripci√≥n**: DeepSpeech, Whisper, Silero, Vosk

1. Fork el proyecto

2. Crea una rama (`git checkout -b feature/nueva-funcionalidad`)- **4GB RAM** m√≠nimo (8GB recomendado para Whisper)- **Transcripci√≥n en tiempo real** con SocketIO

3. Commit tus cambios (`git commit -m 'feat: agregar nueva funcionalidad'`)

4. Push a la rama (`git push origin feature/nueva-funcionalidad`)- **Conexi√≥n a internet** (solo para DeepSpeech)- **Detecci√≥n de fraude con ML** (LogisticRegression + TF-IDF)

5. Abre un Pull Request

- **Interfaz web moderna** con Bootstrap 5

## üìù Licencia

## üìä Dependencias Principales- **Configuraci√≥n flexible** de audio en tiempo real

Este proyecto est√° bajo la Licencia MIT. Ver [LICENSE](LICENSE) para m√°s detalles.

- **Arquitectura modular** f√°cilmente extensible

## üë• Autores

- Flask 3.0.0 + Flask-SocketIO 5.3.6

- **Equipo DTIC** - *Desarrollo inicial*

- SpeechRecognition 3.10.0## üîß Motores Disponibles

## üôè Agradecimientos

- PyAudio 0.2.14

- [SpeechRecognition](https://github.com/Uberi/speech_recognition) por la biblioteca base

- [OpenAI Whisper](https://github.com/openai/whisper) por el modelo de alta precisi√≥n- scikit-learn 1.6.1| Motor | Velocidad | Precisi√≥n | Internet | Recursos |

- [Vosk](https://alphacephei.com/vosk/) por el motor offline

- [Silero](https://github.com/snakers4/silero-models) por los modelos STT- [Opcional] openai-whisper, silero-vad, vosk|-------|-----------|-----------|-----------|-----------|



## üìû Soporte| **DeepSpeech** (Google SR) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚úÖ Requiere | Bajo |



Si encuentras alg√∫n problema o tienes preguntas:## üêõ Soluci√≥n de Problemas| **OpenAI Whisper** | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Alto |



1. Revisa la secci√≥n de [Issues](https://github.com/tu-usuario/DTIC_V4_DeepSpeech/issues)| **Silero STT** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Medio |

2. Lee [INSTALL.md](INSTALL.md) para problemas de instalaci√≥n

3. Abre un nuevo issue si no encuentras soluci√≥n### Micr√≥fono no detectado| **Vosk** (Kaldi) | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚ùå Offline | Bajo |



---- Verificar permisos de micr√≥fono en Windows



**Versi√≥n**: 4.0  - Comprobar que no est√© siendo usado por otra aplicaci√≥n## üöÄ Inicio R√°pido

**√öltima actualizaci√≥n**: Octubre 2025



üé§ **¬°Listo para transcribir con m√∫ltiples motores de √∫ltima generaci√≥n!**

### Motor no disponible### 1. Ejecutar el sistema

- Ejecutar `.\instalar_motores.bat` para instalar dependencias```bash

- Verificar conexi√≥n a internet para DeepSpeech# Doble clic en el archivo:

iniciar_transcriptor.bat

### Error de transcripci√≥n

- Verificar nivel de ruido ambiental# O desde l√≠nea de comandos:

- Ajustar umbral de energ√≠a en configuraci√≥ntranscriptor_env\Scripts\activate

- Cambiar de motor de transcripci√≥npython transcriptor.py

```

## üìù Logs y Debug

### 2. Acceder a la interfaz

El sistema incluye logging detallado:Abrir navegador en: **http://localhost:5003**

- **Panel de debug** en la interfaz web

- **Consola del servidor** con informaci√≥n t√©cnica### 3. Usar el sistema

- **Estados de SocketIO** en tiempo real1. **Seleccionar motor** haciendo clic en las tarjetas

2. **Ajustar configuraci√≥n** de audio si es necesario

---3. **Hacer clic en "Iniciar"** para comenzar transcripci√≥n

4. **Hablar al micr√≥fono** - los resultados aparecen en tiempo real

**Desarrollado por**: Equipo DTIC  

**Versi√≥n**: 4.0  ## ÔøΩ Instalaci√≥n de Motores Adicionales

**√öltima actualizaci√≥n**: Septiembre 2025
Para instalar Whisper, Silero y Vosk (opcional):
```bash
.\instalar_motores.bat
```

### ‚öôÔ∏è **Instalaci√≥n Manual**
```powershell
# Activar entorno virtual
.\transcriptor_env\Scripts\activate

# Instalar motores adicionales
pip install -r requirements_full.txt
```

---

## üéØ Uso del Sistema

### **1. Inicio R√°pido**
```powershell
.\iniciar.bat
```

### **2. Interfaz Web**
1. Abrir navegador en: **`http://localhost:5002`**
2. **Seleccionar Motor**: Elegir entre los 4 motores disponibles
3. **Configurar Audio**: Ajustar par√°metros seg√∫n ambiente
4. **Iniciar Transcripci√≥n**: Presionar "Iniciar" y hablar
5. **Ver Resultados**: Transcripciones en tiempo real con an√°lisis de fraude

### **3. Caracter√≠sticas de la Interfaz**

#### **üéõÔ∏è Panel de Selecci√≥n de Motores**
- Tarjetas visuales para cada motor
- Indicadores de estado (‚úÖ disponible / ‚ö†Ô∏è no instalado)
- Iconos de conectividad (üåê internet / üíæ offline)
- Cambio din√°mico sin interrumpir transcripci√≥n

#### **üîß Configuraci√≥n de Audio en Tiempo Real**
- **Umbral de Energ√≠a**: Sensibilidad del micr√≥fono (300-4000)
- **Pausa Entre Frases**: Tiempo para detectar final (0.1-2.0s)
- **L√≠mite de Frase**: Duraci√≥n m√°xima de grabaci√≥n (3-15s)
- **Timeout de Escucha**: Tiempo de espera sin audio (1-5s)
- **Idioma**: Selecci√≥n de idioma de transcripci√≥n
- **Ajuste Din√°mico**: Adaptaci√≥n autom√°tica al ruido

#### **üõ°Ô∏è Detecci√≥n de Fraude Integrada**
- **Machine Learning**: Modelo entrenado con 60% de threshold
- **Keywords**: Detecci√≥n de palabras clave sospechosas
- **An√°lisis en Tiempo Real**: Cada transcripci√≥n es analizada
- **Indicadores Visuales**: üî¥ Fraude detectado | üü¢ Texto normal

---

## üîß Configuraci√≥n Avanzada

### **Configuraci√≥n Espec√≠fica por Motor**

#### **OpenAI Whisper**
```python
{
    'use_faster_whisper': True,    # Usar faster-whisper (recomendado)
    'model_size': 'base',          # tiny, base, small, medium, large
    'device': 'cpu'                # cpu, cuda
}
```

#### **Silero STT**
```python
{
    'model_language': 'es',        # es, en, de, uk, uz
    'device': 'cpu'                # cpu, cuda
}
```

#### **Vosk (Kaldi)**
```python
{
    'model_path': '/path/to/model', # Ruta al modelo descargado
    'model_language': 'es'          # Idioma del modelo
}
```

### **Descarga de Modelos Vosk**
Para usar Vosk, descarga modelos desde: [https://alphacephei.com/vosk/models](https://alphacephei.com/vosk/models)

---

## üìä Comparativa de Rendimiento

| Caracter√≠stica | DeepSpeech | Whisper | Silero | Vosk |
|----------------|------------|---------|--------|------|
| **Velocidad** | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| **Precisi√≥n** | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| **Internet** | ‚úÖ Requerido | ‚ùå Opcional | ‚ùå No | ‚ùå No |
| **Tama√±o** | 10MB | 1-3GB | 100MB | 50MB-1GB |
| **Idiomas** | 20+ | 90+ | 5 | 20+ |
| **Configuraci√≥n** | F√°cil | Media | Media | Avanzada |

---

## üìÅ Estructura del Proyecto

```
DTIC_V4_DeepSpeech/
‚îú‚îÄ‚îÄ üéØ transcriptor.py              # Sistema principal modular
‚îú‚îÄ‚îÄ üîß engine_manager.py            # Gestor de motores
‚îú‚îÄ‚îÄ üìÅ engines/                     # M√≥dulo de motores
‚îÇ   ‚îú‚îÄ‚îÄ base_engine.py              # Clase abstracta base
‚îÇ   ‚îú‚îÄ‚îÄ deepspeech_engine.py        # Google Speech Recognition
‚îÇ   ‚îú‚îÄ‚îÄ whisper_engine.py           # OpenAI Whisper + Faster-Whisper
‚îÇ   ‚îú‚îÄ‚îÄ silero_engine.py            # Silero STT
‚îÇ   ‚îî‚îÄ‚îÄ vosk_engine.py              # Vosk (Kaldi)
‚îú‚îÄ‚îÄ ü§ñ best_model_lr.joblib         # Modelo ML para fraude
‚îú‚îÄ‚îÄ üî§ vectorizer_tfidf.joblib      # Vectorizador TF-IDF
‚îú‚îÄ‚îÄ üì¶ requirements.txt             # Dependencias b√°sicas
‚îú‚îÄ‚îÄ üì¶ requirements_full.txt        # Dependencias completas
‚îú‚îÄ‚îÄ üöÄ iniciar.bat                  # Launcher del sistema
‚îú‚îÄ‚îÄ üì¶ instalar_motores.bat         # Instalador autom√°tico
‚îî‚îÄ‚îÄ üìÅ transcriptor_env/            # Entorno virtual Python
```

---

## üõ†Ô∏è Soluci√≥n de Problemas

### **‚ùå Error: Motor no se puede cargar**
```powershell
# Instalar dependencias completas
.\instalar_motores.bat

# O manualmente
pip install -r requirements_full.txt
```

### **‚ùå Error: PyAudio no funciona**
```powershell
# Windows: Reinstalar PyAudio
pip uninstall pyaudio
pip install pyaudio
```

### **‚ùå Error: Vosk sin modelos**
1. Descargar modelo desde: https://alphacephei.com/vosk/models
2. Extraer en carpeta `models/`
3. Configurar ruta en la interfaz

### **‚ùå Error: CUDA no disponible**
```powershell
# Instalar PyTorch solo CPU
pip install torch torchaudio --index-url https://download.pytorch.org/whl/cpu
```

---

## üåê API y Endpoints

### **URLs del Sistema**
- **Aplicaci√≥n Principal**: `http://localhost:5002`
- **Panel de Control**: Interfaz web completa

### **API REST Endpoints**
- `GET /api/engines` - Lista de motores disponibles
- `POST /api/change_engine` - Cambiar motor activo
- `GET /api/audio_config` - Configuraci√≥n actual de audio
- `POST /start_listening` - Iniciar transcripci√≥n
- `POST /stop_listening` - Detener transcripci√≥n
- `POST /update_audio_config` - Actualizar configuraci√≥n

### **WebSocket Events**
- `transcription_result` - Resultado con an√°lisis de fraude
- `engine_changed` - Notificaci√≥n de cambio de motor
- `engine_error` - Errores en tiempo real

---

## üîí Detecci√≥n de Fraude

### **Caracter√≠sticas del Sistema**
- **Modelo ML**: Regresi√≥n log√≠stica entrenada
- **Threshold**: 60% de probabilidad para clasificar como fraude
- **Keywords**: Detecci√≥n de palabras clave sospechosas
- **Tiempo Real**: An√°lisis inmediato de cada transcripci√≥n

### **Ejemplos de Detecci√≥n**
- ‚úÖ **Normal**: "Buenos d√≠as, ¬øc√≥mo est√° usted hoy?"
- ‚ö†Ô∏è **Fraude**: "Dinero f√°cil sin riesgo, ganancia garantizada"

### **Indicadores Visuales**
- üü¢ **Texto Normal**: Borde verde, probabilidad baja
- üî¥ **Fraude Detectado**: Borde rojo, probabilidad alta
- üìä **Porcentaje**: Probabilidad de fraude mostrada

---

## üöÄ Caracter√≠sticas T√©cnicas

### **Arquitectura Modular**
- **Strategy Pattern**: Intercambio din√°mico de algoritmos
- **Factory Pattern**: Creaci√≥n autom√°tica de motores
- **Observer Pattern**: Notificaciones en tiempo real

### **Tecnolog√≠as Utilizadas**
- **Backend**: Python Flask + SocketIO
- **Frontend**: Bootstrap 5 + JavaScript
- **Audio**: SpeechRecognition + PyAudio
- **ML**: scikit-learn + joblib
- **Motores**: Google SR, Whisper, Silero, Vosk

### **Gesti√≥n de Recursos**
- **Inicializaci√≥n Lazy**: Motores se cargan solo cuando se usan
- **Fallback Autom√°tico**: Si un motor falla, contin√∫a con otro
- **Gesti√≥n de Memoria**: Limpieza autom√°tica de recursos

---

## üìÑ Dependencias

### **B√°sicas** (requirements.txt)
```
Flask==3.1.2
Flask-SocketIO==5.5.1
SpeechRecognition==3.14.3
PyAudio==0.2.14
joblib==1.5.2
scikit-learn==1.6.1
numpy==2.3.2
scipy==1.16.1
```

### **Completas** (requirements_full.txt)
```
# B√°sicas + Motores adicionales
openai-whisper>=20231117
faster-whisper>=1.0.0
torch>=2.0.0
torchaudio>=2.0.0
silero>=0.4.1
vosk>=0.3.45
librosa>=0.10.0
soundfile>=0.12.0
transformers>=4.30.0
```

---

## üéØ Instrucciones de Uso R√°pido

### **Para Usuario B√°sico**
1. **Ejecutar**: `.\iniciar.bat`
2. **Abrir**: `http://localhost:5002`
3. **Configurar**: Ajustar audio seg√∫n ambiente
4. **Usar**: Presionar "Iniciar" y hablar

### **Para Usuario Avanzado**
1. **Instalar Motores**: `.\instalar_motores.bat`
2. **Seleccionar Motor**: Elegir seg√∫n necesidades
3. **Configurar**: Ajustar par√°metros espec√≠ficos
4. **Personalizar**: Descargar modelos adicionales

### **Para Desarrollador**
1. **Estudiar**: Arquitectura en `/engines/`
2. **Extender**: Crear nuevos motores
3. **Integrar**: Usar API REST/WebSocket
4. **Personalizar**: Modificar detecci√≥n de fraude

---

## üìû Soporte

- **Sistema Listo**: Funciona inmediatamente con motor b√°sico
- **Instalaci√≥n Simple**: Script autom√°tico para motores adicionales
- **Documentaci√≥n**: Comentarios en c√≥digo para desarrollo
- **Arquitectura Limpia**: F√°cil de extender y mantener

---

**üé§ El sistema est√° listo para transcribir con m√∫ltiples motores de √∫ltima generaci√≥n!**